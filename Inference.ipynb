{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Inference.ipynb","provenance":[{"file_id":"10JKK-LX9-Z_GP9bwy8GHhGX2VSAl00A8","timestamp":1636707242481}]}},"cells":[{"cell_type":"code","metadata":{"id":"OCjZwlsGTMFG"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"OCjZwlsGTMFG","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-11-08T05:00:37.379865Z","start_time":"2021-11-08T05:00:37.373668Z"},"id":"municipal-parcel","executionInfo":{"status":"ok","timestamp":1636739900852,"user_tz":-330,"elapsed":1672,"user":{"displayName":"Siva Sankar S ch20b103","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09310026757114527063"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import RegexpTokenizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn import preprocessing\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","from sklearn.pipeline import Pipeline\n","from itertools import compress\n","from sklearn.preprocessing import StandardScaler\n","%matplotlib notebook\n","stemmer = PorterStemmer()\n","tokenizer = RegexpTokenizer(r'\\w+')\n","train_path = '/content/drive/MyDrive/TechSoc Submission/train.csv'\n","test_path = '/content/drive/MyDrive/TechSoc Submission/test.csv'\n","stopwords_path = '/content/drive/MyDrive/TechSoc Submission/stopwords.txt'\n","save_path='/content/drive/MyDrive/TechSoc Submission/final.csv'\n","model_path='/content/drive/MyDrive/TechSoc Submission/MyModel.pkl'\n","stopwords = []\n","file = open(stopwords_path, \"r\")\n","for line in file:\n","      word=line.strip()\n","      stopwords.append(stemmer.stem(word))\n","def PreProcesser(df):\n","    df = df.drop(columns = ['title','uid'])\n","    df['TolWords']= df['content'].apply(lambda x: len(x.split(' ')))\n","    df['TolSentance']=df['content'].apply(lambda x: len(x))\n","    df['AvgWordLen']= df['content'].apply(lambda x: np.mean([len(word)  for word in x.split(' ') ]))\n","    df['TotStopwords']= df['content'].apply(lambda x:len(list(compress(x.split(),[word in stopwords  for word in x.split()]))))\n","    df['content']=df['content'].apply(lambda x: TreebankWordDetokenizer().detokenize( stemmer.stem(word) for word in tokenizer.tokenize(x) ))\n","    df['content']= df['content'].apply(lambda x:TreebankWordDetokenizer().detokenize(list(compress(x.split(), [word not in stopwords  for word in x.split()]))))\n","    df['TolWordsFin']= df['content'].apply(lambda x: len(x.split(' ')))\n","    df['TolSentanceFin']=df['content'].apply(lambda x: len(x))\n","    df['AvgWordLenFin']= df['content'].apply(lambda x: np.mean([len(word)  for word in x.split(' ') ]))\n","    return df\n","\n","\n","# import required libraries"],"id":"municipal-parcel","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x9VkRyF1SCcE","executionInfo":{"status":"ok","timestamp":1636739944477,"user_tz":-330,"elapsed":2800,"user":{"displayName":"Siva Sankar S ch20b103","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09310026757114527063"}},"outputId":"7dee84fe-5633-44e8-9b75-eee0ceea0be2"},"source":["from dill import load_session\n","load_session(model_path)\n","df_pred = pd.read_csv(test_path)"],"id":"x9VkRyF1SCcE","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaPrseIDS_n-","executionInfo":{"status":"ok","timestamp":1636739871652,"user_tz":-330,"elapsed":25537,"user":{"displayName":"Siva Sankar S ch20b103","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09310026757114527063"}},"outputId":"236d275e-1a46-441d-f36c-7444a3a08a39"},"source":[""],"id":"oaPrseIDS_n-","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-11-08T05:02:59.207247Z","start_time":"2021-11-08T05:02:59.197840Z"},"id":"bottom-gibson","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636740003304,"user_tz":-330,"elapsed":56973,"user":{"displayName":"Siva Sankar S ch20b103","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09310026757114527063"}},"outputId":"cf468afc-a50b-41ff-8821-ffb2510a42cd"},"source":["%%time\n","print(\"Code for Inference\")\n","df_pred = PreProcesser(df_pred)\n","t = Vectorizer.transform(df_pred['content'])\n","t1=t[:,ind]\n","df_f=pd.DataFrame.sparse.from_spmatrix(t1)\n","df_fin = pd.concat([df_pred,df_f],axis=1)\n","X_pred = df_fin.drop(columns=['content'])\n","X_pred = scaler.transform(X_pred)\n","pred = clf.predict(X_pred)\n","# Full Code for running your inference (including any preprocessing you need to do on the test set)\n","# In this Cell as a comment also mention the CPU and GPU of the system you are using to run this inference\n","# CPU:  Standard google colab notebook:   \n","# GPU:  Standard google colab notebook:  "],"id":"bottom-gibson","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Code for Inference\n","CPU times: user 56.9 s, sys: 418 ms, total: 57.3 s\n","Wall time: 56.8 s\n"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-11-08T05:03:23.210476Z","start_time":"2021-11-08T05:03:23.205309Z"},"id":"fossil-crash","executionInfo":{"status":"ok","timestamp":1636740087481,"user_tz":-330,"elapsed":1227,"user":{"displayName":"Siva Sankar S ch20b103","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09310026757114527063"}}},"source":["df_fin = pd.DataFrame(pred,columns=['target_ind'])\n","df_fin.index.name='uid'\n","df_fin.to_csv(save_path,index=True)"],"id":"fossil-crash","execution_count":10,"outputs":[]}]}